# =============================================================================
# WaveGo Agent Configuration
# =============================================================================
# This file contains all hardware and software configuration parameters.
# Modify these values according to your setup.

# -----------------------------------------------------------------------------
# Hardware Configuration
# -----------------------------------------------------------------------------
hardware:
  serial:
    port: "/dev/ttyS0"
    baudrate: 115200
    timeout: 1.0

  camera:
    device_id: 0
    width: 640
    height: 480
    fps: 30

  audio:
    # Microphone settings
    mic_device_index: null  # null for default device
    sample_rate: 16000
    chunk_size: 1024
    record_seconds: 5  # Max recording time for voice input
    
    # Speaker settings
    speaker_device_index: null  # null for default device

# -----------------------------------------------------------------------------
# LLM API Configuration
# -----------------------------------------------------------------------------
llm:
  provider: "openai"  # Options: "openai", "azure", "local"
  model: "gpt-4o-mini"  # Recommended for cost/performance balance
  api_key_env: "OPENAI_API_KEY"  # Environment variable name
  max_tokens: 500
  temperature: 0.7
  
  # System prompt for the robot assistant
  system_prompt: |
    You are an intelligent assistant controlling a quadruped robot dog called WaveGo.
    You can help the user by executing movement commands and answering questions.
    
    When the user gives you a command, analyze it and respond with a JSON object containing:
    - "intent": The action type (move, look, stop, query, gesture, light, unknown)
    - "action": Specific action (forward, backward, left, right, up, down, stop, jump, handshake, steady)
    - "parameters": Any parameters like distance, speed, duration, color
    - "reply": A natural language response to the user
    
    Available actions:
    - Movement: forward, backward, left, right, stop
    - Head control: look_up, look_down, look_left, look_right
    - Gestures: jump, handshake, steady
    - Lights: Set LED color (blue, red, green, yellow, cyan, magenta, cyber, off) - robot has dual lights
    
    Consider the vision_state when making decisions:
    - If obstacle_ahead is true, do NOT move forward
    - If a target object is detected, you can report its position
    
    Always respond in valid JSON format.

# -----------------------------------------------------------------------------
# Speech Recognition Configuration
# -----------------------------------------------------------------------------
speech:
  # STT Engine: "google", "whisper_api", "whisper_local", "vosk"
  stt_engine: "google"
  
  # Wake word (optional, set to null to disable)
  wake_word: null  # e.g., "hey robot"
  
  # Language
  language: "en-US"
  
  # Whisper settings (if using whisper)
  whisper:
    model: "base"  # tiny, base, small, medium, large
    api_key_env: "OPENAI_API_KEY"

# -----------------------------------------------------------------------------
# Text-to-Speech Configuration  
# -----------------------------------------------------------------------------
tts:
  # TTS Engine: "pyttsx3", "gtts", "openai"
  engine: "pyttsx3"
  
  # Voice settings
  voice_rate: 150  # Words per minute
  voice_volume: 0.9  # 0.0 to 1.0
  
  # OpenAI TTS settings (if using)
  openai_tts:
    model: "tts-1"
    voice: "alloy"  # alloy, echo, fable, onyx, nova, shimmer

# -----------------------------------------------------------------------------
# Vision Processing Configuration
# -----------------------------------------------------------------------------
vision:
  # Enable/disable vision processing
  enabled: true
  
  # Obstacle detection
  obstacle_detection:
    enabled: true
    min_area: 5000  # Minimum contour area to consider as obstacle
    roi_top: 0.3    # Region of interest (top 30% to 70% of frame)
    roi_bottom: 0.7
  
  # Color detection (HSV ranges)
  color_detection:
    enabled: true
    default_color:
      h_center: 34  # Yellow-ish
      h_range: 15
      s_min: 100
      s_max: 255
      v_min: 100
      v_max: 255
  
  # Face detection
  face_detection:
    enabled: true
    scale_factor: 1.2
    min_neighbors: 5
    min_size: [20, 20]
  
  # Motion detection
  motion_detection:
    enabled: true
    min_area: 2000
    threshold: 25

# -----------------------------------------------------------------------------
# Agent Behavior Configuration
# -----------------------------------------------------------------------------
agent:
  # Safety constraints
  safety:
    obstacle_stop: true  # Stop if obstacle detected ahead
    max_continuous_move_time: 5.0  # Max seconds for continuous movement
    
  # Movement parameters
  movement:
    default_speed: 100
    default_duration: 1.0  # Default movement duration in seconds
    
  # Response behavior
  response:
    speak_confirmation: true  # Speak before executing action
    speak_completion: false   # Speak after action complete

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "wavego_agent.log"
  console: true
